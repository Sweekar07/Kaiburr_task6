# Kaiburr_task6
Task 6. Data Science example.

## Task 6: Data Science Example

Perform a Text Classification on the [consumer complaint dataset](https://catalog.data.gov/dataset/consumer-complaint-database) into the following categories:

- **0:** Credit reporting, repair, or other
- **1:** Debt collection
- **2:** Consumer Loan
- **3:** Mortgage

### Steps to be followed:

1. **Explanatory Data Analysis and Feature Engineering**
2. **Text Pre-Processing**
3. **Selection of Multi Classification model**
4. **Comparison of model performance**
6. **Model Evaluation**
7. **Prediction**

### Comparison of Model Performance:

After rigorously testing various supervised learning algorithms including:

- Linear Regression
- Logistic Regression
- Support Vector Machines (SVM)
- Decision Trees
- Random Forest
- Gradient Boosted Trees (GBT)
- AdaBoost
- Naive Bayes
- k-Nearest Neighbors (k-NN)
- Neural Networks
- ... [and others you might have used]

I observed that the **ExtraTree Classifier** outperformed all other models, achieving an accuracy rate of 88%. This makes it a superior choice for this specific problem.

> **Note:** I also considered training the model using BERT (Bidirectional Encoder Representations from Transformers) due to its potential to further enhance classification performance. However, I encountered memory constraints during the process, which prevented its effective implementation and evaluation.
